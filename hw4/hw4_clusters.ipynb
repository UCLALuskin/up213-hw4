{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8521be31",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b09c25877d32ac7c79f091e983cc077",
     "grade": false,
     "grade_id": "cell-efc8e2cd6c423ad3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Homework 4: Cluster analysis\n",
    "\n",
    "In this assignment, we'll do cluster analysis of transit agencies. Our goal: identify whether there are groups of \"more similar\" agencies. This type of analysis might help us identify a peer group for a particular agency, against which it can be benchmarked.\n",
    "\n",
    "We'll use the [2023 National Transit Database](https://www.transit.dot.gov/ntd), which compiles the data that each transit agencies must report to the Federal Transit Administration.\n",
    "\n",
    "The relevant spreadsheets are in your repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32fd724",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4793e0ecd2b3e9524fa7c5c8981fc596",
     "grade": false,
     "grade_id": "cell-22802eecdb3ed8cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please help me grade by observing the following:\n",
    " \n",
    "* Do not rename this notebook (that messes up the autograder)\n",
    "* Do not include large sections of output (that makes it hard to find your code). For example, use `df.head()` to show the first few rows, rather than printing an entire dataframe. The same goes for printing long strings.\n",
    "* Follow the same guidelines for ChatGPT / LLM usage as in previous assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c2d6b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee1c2b378cfa3f0b17d6f351935efc21",
     "grade": false,
     "grade_id": "cell-5cb8d66382de344e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Load in `2023 Agency Information_0.xlsx.xlsx` to a `pandas` DataFrame called `agency_info`.\n",
    "\n",
    "You can use the `pd.read_excel()` command, which works in the same way as `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4457415",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45e0032e3e5158a0c20bde153aaca842",
     "grade": false,
     "grade_id": "cell-9d1ff6bbc326c6c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "agency_info = 999 # replace with your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5425b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0233ac840264a0cb612a6146cf6d040",
     "grade": true,
     "grade_id": "cell-bdf98bf21a1a7205",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "\n",
    "print(len(agency_info))\n",
    "print(agency_info.columns)\n",
    "print(len(agency_info.columns))\n",
    "\n",
    "assert len(agency_info)==2899\n",
    "assert 'NTD ID' in agency_info.columns\n",
    "assert len(agency_info.columns)==43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30637f1-461e-49c8-a78b-ef84b50f4df1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbb83baade2ebe04b96fefb63ee121a8",
     "grade": false,
     "grade_id": "cell-6ec260b72e883fd5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There are two duplicated NTD ids - it's not clear why. You will need to drop them to avoid double counting in subsequent steps. I suggest you do it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923e3dd-a4d0-4cb8-b1c0-df79ab109410",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59337e537b4f0468d38efb0c025a0229",
     "grade": false,
     "grade_id": "cell-9d40449a599cf8d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "agency_info = agency_info.drop_duplicates(subset='NTD ID') # will keep only the first, where there are duplicate ids\n",
    "assert agency_info['NTD ID'].is_unique # check it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6627fa7a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4579a33e3c2901ba2c1204a5edf7eed0",
     "grade": false,
     "grade_id": "cell-370cbc18bb4fb2a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Load in the `service_bymode_2023.csv` file to a dataframe called `service` in the same way.\n",
    "\n",
    "Most of the columns should be self explanatory, but you may need to refer to the [data dictionary](https://www.transit.dot.gov/ntd/data-product/2023-ntd-database-file-dictionary) or [glossary](https://www.transit.dot.gov/ntd/national-transit-database-ntd-glossary).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404e77c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf5119de314483a22ea27dddf62cad53",
     "grade": false,
     "grade_id": "cell-3c2b767eb149a9bb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "service = 999 # replace with your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f8a42",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf13c80c90c06b1d3b8ce37149c5e14e",
     "grade": true,
     "grade_id": "cell-3ca0f3c317f75d70",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "\n",
    "print(len(service))\n",
    "print(len(service.columns))\n",
    "\n",
    "assert len(service)==3681\n",
    "assert '_5_digit_ntd_id' in service.columns\n",
    "assert len(service.columns)==46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c9510-793c-45c2-8614-0a72527fa3e6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29ede7e1d02f873cee512bf897595975",
     "grade": false,
     "grade_id": "cell-98cf1096178c0e3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You probably notice that there are many more rows in the `service` dataframe. If you look at the first few rows, you can see that each agency has different rows for:\n",
    "* different modes (e.g. `MB` is motorbus)\n",
    "* different types of service (directly operated is `DR` and contracted / purchased is `PT`)\n",
    "\n",
    "If we do a join with `agency_info`, we'll end up with a 1:many join. That's not as useful if we want to cluster transit agencies.\n",
    "\n",
    "So let's aggregate the `service` data first. Create a new dataframe, `service_agg`, that:\n",
    "1. Keeps only the rows for Buses/Trolleybuses/Commuter Buses/Bus Rapid Transit (`mode` is `MB`, `TB`, `CB` or `RB`, so we are comparing like with like). Hint: the `in` operator is useful here.\n",
    "2. Groups by the agency (NTD ID, called `_5_digit_ntd_id`) and sums these columns:\n",
    "\n",
    "* Unlinked Passenger Trips (`sum_unlinked_passenger_trips_upt`)\n",
    "* Passenger Miles (`sum_passenger_miles`)\n",
    "* Revenue Miles (`sum_actual_vehicles_passenger_car_revenue_miles`), i.e., how distance traveled while in revenue service (vehicles/cars here refers to buses/train cars, not automobiles)\n",
    "* Deadhead Miles (`sum_actual_vehicles_passenger_deadhead_miles`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe665c11",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17c811ea81910e9dfc59864832bd525f",
     "grade": false,
     "grade_id": "cell-0f3828cd3561b6fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "service_agg = 999 # replace with your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc545b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "911a04f0af54c22bb300e5591062e302",
     "grade": true,
     "grade_id": "cell-0a13773f89540dd6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "\n",
    "print(len(service_agg))\n",
    "print(service_agg.sum_unlinked_passenger_trips_upt.sum())\n",
    "\n",
    "assert(len(service_agg)==1204)\n",
    "assert service_agg.index.name=='_5_digit_ntd_id'\n",
    "assert service_agg.sum_unlinked_passenger_trips_upt.sum() == 3475162210"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47914980",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e67b23f0765467c12ba582977705f55",
     "grade": false,
     "grade_id": "cell-58dd43b7922e769b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, join your `service_agg` dataframe to your `agency_info` dataframe. Call the new dataframe `transit`. \n",
    "\n",
    "You should note that the `agency_info` has more rows that `service_agg`, because some small agencies aren't required to report service information. Drop those - you can do either an inner join, or a left join to `service_agg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d703c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80212a5039e45965e9ad93fe4a52a7ac",
     "grade": false,
     "grade_id": "cell-755b9b132e3ebb63",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "transit = 999  # replace with your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da28145",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e46049feb94d34cc74b26cc9317ed0fe",
     "grade": true,
     "grade_id": "cell-5dcf1b144440f7a9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "\n",
    "print(len(transit))\n",
    "print(transit.sum_unlinked_passenger_trips_upt.sum())\n",
    "print(transit.Population.sum())\n",
    "\n",
    "assert len(transit)==1204\n",
    "assert transit.sum_unlinked_passenger_trips_upt.sum() == 3475162210\n",
    "assert transit.Population.sum() == 2109627865\n",
    "#why isn't this the same sum as above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf21ac4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a08fbffa4d160228b9844906fa1378c",
     "grade": false,
     "grade_id": "cell-841eb3f66ed45b8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The final data preparation step is to standardize the variables. Some of them are strings (use `transit.info()` to take a look). But let's standardize the numeric ones that we might want to use to cluster.\n",
    "\n",
    "Create a data frame, `df_to_cluster`, with the following standardized variables: \n",
    "* sum_unlinked_passenger_trips_upt\n",
    "* sum_passenger_miles\n",
    "* sum_actual_vehicles_passenger_car_revenue_miles \n",
    "* sum_actual_vehicles_passenger_deadhead_miles \n",
    "* Population\n",
    "* Density\n",
    "* Total VOMS (vehicles operated in maximum service)\n",
    "\n",
    "(See Lecture 14 on neural networks for how to standardize.)\n",
    "\n",
    "It should still be indexed by NTD ID (`_5_digit_ntd_id`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bda177",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa40f885f39446bbb33193726831352e",
     "grade": false,
     "grade_id": "cell-81e7692420bfc71c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# your code here\n",
    "df_to_cluster = 999 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772ccf2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "141821495da311022e469b3988cd7634",
     "grade": true,
     "grade_id": "cell-9ab71dec9556a50e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "print(len(df_to_cluster))\n",
    "print(df_to_cluster.Population.mean())\n",
    "print(df_to_cluster.sum_unlinked_passenger_trips_upt.mean())\n",
    "print(len(df_to_cluster.columns))\n",
    "\n",
    "assert len(df_to_cluster)==1204\n",
    "assert df_to_cluster.Population.mean().round(5)==0\n",
    "assert df_to_cluster.sum_unlinked_passenger_trips_upt.mean().round(5)==0\n",
    "assert len(df_to_cluster.columns) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72fff1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a37b500938604bee12615fadeea9c97",
     "grade": false,
     "grade_id": "cell-2ca67b40aeb5676f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's start with 5 clusters. Use the `KMeans` algorithm to assign each observation to a cluster.\n",
    "\n",
    "Add the cluster number (id) to a new column in your original `df_to_cluster` dataframe. Call the new column `cluster_id`.\n",
    "\n",
    "*Hint:* Drop the Null values before trying to cluster. And see lecture 15 (clustering) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c3ed0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0cc3fb05c1ae592ba1cc3b31094a0ed",
     "grade": false,
     "grade_id": "cell-9287b9deadcb782d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270a41f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e4038a8b7199fbbe532135be577e0ac",
     "grade": true,
     "grade_id": "cell-f304596d7719f05a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "print(df_to_cluster.groupby('cluster_id').size())\n",
    "\n",
    "assert len(df_to_cluster.groupby('cluster_id').size())==5\n",
    "assert df_to_cluster.groupby('cluster_id').size().min()==1\n",
    "cmax = df_to_cluster.groupby('cluster_id').size().max()\n",
    "assert cmax>700 and cmax<710"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6163116",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc49dee6572f0d8a2bbe42cd7488353e",
     "grade": false,
     "grade_id": "cell-870146bca6702e7a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You should have one cluster that is a single transit agency. And another that is just 2 agencies.\n",
    "\n",
    "What's the name of the agency that's in the cluster of one? (*Hint*: you can get its id from `df_to_cluster`, and its name from `transit`, your original dataframe.)\n",
    "Comment on whether this seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb8d72",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a6222ae4f72939487d096b7541fe68d",
     "grade": true,
     "grade_id": "cell-9fdc88d79e0cfcc6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e12277",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7ebaff685fa3a50d51e255068f8cb0e",
     "grade": false,
     "grade_id": "cell-3b541129eae9eb71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Create a radar plot that shows how your clusters relate to your 7 variables. Here's the function to create a radar plot that we used in the lecture.\n",
    "\n",
    "*Hint*: You'll need to drop the `cluster_id` column first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eabd8b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a45f06f1896d6d989fd00ec9e264eb69",
     "grade": false,
     "grade_id": "cell-e2442474bd8062de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# code from https://matplotlib.org/stable/gallery/specialty_plots/radar_chart.html\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "\n",
    "def radar_factory(num_vars, frame='circle'):\n",
    "    \"\"\"\n",
    "    Create a radar chart with `num_vars` axes.\n",
    "\n",
    "    This function creates a RadarAxes projection and registers it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_vars : int\n",
    "        Number of variables for radar chart.\n",
    "    frame : {'circle', 'polygon'}\n",
    "        Shape of frame surrounding axes.\n",
    "\n",
    "    \"\"\"\n",
    "    # calculate evenly-spaced axis angles\n",
    "    theta = np.linspace(0, 2*np.pi, num_vars, endpoint=False)\n",
    "\n",
    "    class RadarAxes(PolarAxes):\n",
    "\n",
    "        name = 'radar'\n",
    "        # use 1 line segment to connect specified points\n",
    "        RESOLUTION = 1\n",
    "\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            # rotate plot such that the first axis is at the top\n",
    "            self.set_theta_zero_location('N')\n",
    "\n",
    "        def fill(self, *args, closed=True, **kwargs):\n",
    "            \"\"\"Override fill so that line is closed by default\"\"\"\n",
    "            return super().fill(closed=closed, *args, **kwargs)\n",
    "\n",
    "        def plot(self, *args, **kwargs):\n",
    "            \"\"\"Override plot so that line is closed by default\"\"\"\n",
    "            lines = super().plot(*args, **kwargs)\n",
    "            for line in lines:\n",
    "                self._close_line(line)\n",
    "\n",
    "        def _close_line(self, line):\n",
    "            x, y = line.get_data()\n",
    "            # FIXME: markers at x[0], y[0] get doubled-up\n",
    "            if x[0] != x[-1]:\n",
    "                x = np.append(x, x[0])\n",
    "                y = np.append(y, y[0])\n",
    "                line.set_data(x, y)\n",
    "\n",
    "        def set_varlabels(self, labels):\n",
    "            self.set_thetagrids(np.degrees(theta), labels)\n",
    "\n",
    "        def _gen_axes_patch(self):\n",
    "            # The Axes patch must be centered at (0.5, 0.5) and of radius 0.5\n",
    "            # in axes coordinates.\n",
    "            if frame == 'circle':\n",
    "                return Circle((0.5, 0.5), 0.5)\n",
    "            elif frame == 'polygon':\n",
    "                return RegularPolygon((0.5, 0.5), num_vars,\n",
    "                                      radius=.5, edgecolor=\"k\")\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "        def _gen_axes_spines(self):\n",
    "            if frame == 'circle':\n",
    "                return super()._gen_axes_spines()\n",
    "            elif frame == 'polygon':\n",
    "                # spine_type must be 'left'/'right'/'top'/'bottom'/'circle'.\n",
    "                spine = Spine(axes=self,\n",
    "                              spine_type='circle',\n",
    "                              path=Path.unit_regular_polygon(num_vars))\n",
    "                # unit_regular_polygon gives a polygon of radius 1 centered at\n",
    "                # (0, 0) but we want a polygon of radius 0.5 centered at (0.5,\n",
    "                # 0.5) in axes coordinates.\n",
    "                spine.set_transform(Affine2D().scale(.5).translate(.5, .5)\n",
    "                                    + self.transAxes)\n",
    "                return {'polar': spine}\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "    register_projection(RadarAxes)\n",
    "    return theta\n",
    "\n",
    "def radar_plot(kmeans, df_scaled):\n",
    "    N  = kmeans.cluster_centers_.shape[1]  # number of columns / variables\n",
    "    k = kmeans.n_clusters\n",
    "    theta = radar_factory(N, frame='polygon')\n",
    "    data = kmeans.cluster_centers_.T\n",
    "    spoke_labels = [col for col in df_scaled.columns if col!='cluster_id']\n",
    "    fig, ax = plt.subplots(figsize=(9, 9),\n",
    "                                subplot_kw=dict(projection='radar'))\n",
    "    fig.subplots_adjust(wspace=0.25, hspace=0.20, top=0.85, bottom=0.05)\n",
    "\n",
    "    ax.plot(theta, data) #, color=color)\n",
    "    ax.set_varlabels(spoke_labels)\n",
    "\n",
    "    # add legend relative to top-left plot\n",
    "    labels = ['Cluster {}'.format(kk) for kk in range(k)]\n",
    "    ax.legend(labels, loc=(0.9, .95),\n",
    "                                labelspacing=0.1, fontsize='small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20e7fb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fceb5babefcc0a8818fe600da01d6f6",
     "grade": true,
     "grade_id": "cell-fface58e302ba59b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7e403",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "008202b1c1bb5381eef5812a9fa59467",
     "grade": false,
     "grade_id": "cell-fc50446c253e055e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Comment in a few bullet points or sentences. How would you intepret and name each cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7172c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e241be0983a805fa8b39a37198148b66",
     "grade": true,
     "grade_id": "cell-a2c2c5e529ae0120",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc0c5d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa36cadb1d558eedb0a12f14507c9157",
     "grade": false,
     "grade_id": "cell-8efdce74f123d54e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Challenge Problem\n",
    "\n",
    "Remember, you need to do at least two of these challenge problems this quarter.\n",
    "\n",
    "This challenge problem is open ended for you to take in a direction that you are most interested in. Here are some suggestions (do 1 or 2 of these):\n",
    "* Create some dummy variables and use them to cluster. For example, the reporter type and reporting module might be useful\n",
    "* Analyze how your clusters vary by state (a field in your `transit` dataframe). For example, you might do a stacked bar chart of the number of transit agencies in each cluster by state. (Google \"pandas stacked bar\".)\n",
    "* Explore different numbers of clusters\n",
    "* Map your clusters. Your dataframe doesn't have geographic coordinates, but you could join the `Zip Code` field to [this handy dataset](https://hudgis-hud.opendata.arcgis.com/datasets/d032efff520b4bf0aa620a54a477c70e_0/about) that gives the centroids of each zip code.\n",
    "\n",
    "Write some brief interpretation in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d5c47",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96d901b4bdbd4681dc28342a03f3c72a",
     "grade": true,
     "grade_id": "cell-01d5786b60ed43fd",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
